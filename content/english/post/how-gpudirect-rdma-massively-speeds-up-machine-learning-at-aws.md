---
title: "How GPUdirect RDMA massively speeds up machine learning at AWS"
date: 2023-03-09T15:52:21+0000
# post thumb
images:
    - "images/post/o_noqdK5Sdc.png"
author: "Brendan Bouffler"
# description
description: " (reposted from HPC Tech Shorts Youtube channel)"
video_id: "o_noqdK5Sdc"
layout: "video"
# Taxonomies
categories: [ "AI/ML",  "AWS ParallelCluster",  "Amazon NICE DCV",  "Elastic Fabric Adapter",  "Life Sciences", ]
tags: [ "CPUs",  "DCV",  "EC2",  "EFA",  "GPUdirect",  "GPUs",  "HPC",  "High Performance Computing",  "Lustre",  "ML",  "MPI",  "NVIDIA",  "ParallelCluster",  "RDMA",  "Schedulers",  "Storage",  "autoscaling",  "bioinformatics",  "cloud computing",  "elastic",  "elastic fabric adapter",  "infiniband",  "machine learning",  "model training",  "p4d",  "p4de",  "scientific computing",  "technical computing",  "tightly-coupled",  "virtualization",  "vizualization",  "techshorts", ]
type: "regular" # available type (regular or featured)
draft: false
---

GPUdirect RDMA was invented to massively speed up the ML frameworks that so many customers use to train their models using our large fleets of NVIDIA GPUs.

Amr Ragab from EC2 Engineering took a few minutes at SC'22 to explain to us how it works - and how easy it is to take advantage of.

If you have ideas for technical topics you'd like to see us cover in a future show, let us know by finding us on Twitter (@TechHpc) and DM'ing us with your idea.

{{< youtube o_noqdK5Sdc >}}