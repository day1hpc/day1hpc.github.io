<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI/ML on Day 1 HPC (Staging)</title>
    <link>https://d175uvn6dnkepf.cloudfront.net/categories/ai/ml.html</link>
    <description>Recent content in AI/ML on Day 1 HPC (Staging)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://d175uvn6dnkepf.cloudfront.net/categories/ai/ml/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>NCCL on EFA makes the ML world go around in the cloud</title>
      <link>https://d175uvn6dnkepf.cloudfront.net/post/nccl-on-efa-makes-the-ml-world-go-around-in-the-cloud.html</link>
      <pubDate>Thu, 30 Jun 2022 17:05:07 +0000</pubDate>
      
      <guid>https://d175uvn6dnkepf.cloudfront.net/post/nccl-on-efa-makes-the-ml-world-go-around-in-the-cloud.html</guid>
      <description>Machine Learning is a huge workload, and one of the most demanding when it comes to scaling to thousands (and thousands) of CPUs. Some of the largest workloads customers run in the cloud are deep learning models, which require huge numbers of GPUs and saturate the networks connecting them.
To make all that work on AWS, NVIDIA&amp;rsquo;s collectives communications library (NCCL) relies on libfabrics to speak to the EFA hardware that makes up EC2&amp;rsquo;s high performance interconnect.
Rashika Kheria leads the team in Annapurna that handles this interface, ensuring your models, using all your favorite frameworks, scale really nicely to as far as your imagination allows (well, maybe a little further). She came to Tech Shorts to tell us how that works.
If you have ideas for technical topics you&amp;rsquo;d like to see us cover in a future show, let us know by finding us on Twitter (@TechHpc) and DM&amp;rsquo;ing us with your idea.</description>
    </item>
    
    <item>
      <title>Bayesian models and half a million cores - what&#39;re you waiting for?</title>
      <link>https://d175uvn6dnkepf.cloudfront.net/post/bayesian-models-and-half-a-million-cores-whatre-you-waiting-for.html</link>
      <pubDate>Fri, 24 Jun 2022 14:59:17 +0000</pubDate>
      
      <guid>https://d175uvn6dnkepf.cloudfront.net/post/bayesian-models-and-half-a-million-cores-whatre-you-waiting-for.html</guid>
      <description>The Ampersand Data Science team had a challenge: their Bayesian statistical models needed more than half a million core-hours of runtime, regularly, if they were to get an answer fast enough for it to be useful to their customers.
Scaling to a million core or more isn&amp;rsquo;t really a challenge now (thanks to Amazon EC2). The hard part is all the code pipelines and plumbing - and the management of the entire thing when it&amp;rsquo;s in flight.
Daniel Gerlanc (Senior Director for Data Science) and Jeffrey Enos (Senior Machine Learning Engineer) swung by the Tech Shorts virtual watercooler to tell us how it worked, what was most surprising, and which bits made all the difference.
There&amp;rsquo;s also a blog that was posted last week which talks to some of this too. Worth a read: https://aws.amazon.com/blogs/hpc/bayesian-ml-models-at-scale-with-aws-batch/
If you have ideas for technical topics you&amp;rsquo;d like to see us cover in a future show, let us know by finding us on Twitter (@TechHpc) and DM&amp;rsquo;ing us with your idea.</description>
    </item>
    
    <item>
      <title>Bayesian ML Models at Scale with AWS Batch</title>
      <link>https://d175uvn6dnkepf.cloudfront.net/post/bayesian-ml-models-at-scale-with-aws-batch.html</link>
      <pubDate>Tue, 14 Jun 2022 00:00:00 -0700</pubDate>
      
      <guid>https://d175uvn6dnkepf.cloudfront.net/post/bayesian-ml-models-at-scale-with-aws-batch.html</guid>
      <description>Ampersand is a data-driven TV advertising technology company that provides aggregated TV audience impression insights and planning on 42 million households, in every media market, across more than 165 networks and apps and in all dayparts (broadcast day segments). The Ampersand Data Science team estimated that building their statistical models would require up to 600,000 physical CPU hours to run, which would not be feasible without using a massively parallel and large-scale architecture in the cloud. AWS Batch enabled Ampersand to compress their time of computation over 500x through massive scaling while optimizing their costs using Amazon EC2 Spot. In this blog post, we will provide an overview of how Ampersand built their TV audience impressions (“impressions”) models at scale on AWS, review the architecture they have been using, and discuss optimizations they conducted to run their workload efficiently on AWS Batch.</description>
    </item>
    
    <item>
      <title>What makes the AWS Graviton 3 so interesting to HPC and AI/ML customers?</title>
      <link>https://d175uvn6dnkepf.cloudfront.net/post/what-makes-the-aws-graviton-3-so-interesting-to-hpc-and-aiml-customers.html</link>
      <pubDate>Thu, 05 May 2022 16:35:59 +0000</pubDate>
      
      <guid>https://d175uvn6dnkepf.cloudfront.net/post/what-makes-the-aws-graviton-3-so-interesting-to-hpc-and-aiml-customers.html</guid>
      <description>The AWS Graviton 3 will be launched this year as part of the new C7g instance. Inside this chip are some interesting innovations that already have a lot of HPC and AI/ML customers interested.
We sat down with Olly Perks, who recently joined AWS HPC Engineering from Arm, to discuss what&amp;rsquo;s most interesting. This is the first of a series of Tech Shorts covering the Graviton 3 architecture. We&amp;rsquo;ll deep dive on techniques and tools for getting the most out of these CPUs.
If you have ideas for technical topics you&amp;rsquo;d like to see us cover in a future show, let us know by finding us on Twitter (@TechHpc) and DM&amp;rsquo;ing us with your idea.</description>
    </item>
    
    <item>
      <title>AI-based drug discovery with Atomwise and WEKA Data Platform</title>
      <link>https://d175uvn6dnkepf.cloudfront.net/post/ai-based-drug-discovery-with-atomwise-and-weka-data-platform.html</link>
      <pubDate>Tue, 12 Apr 2022 00:00:00 -0700</pubDate>
      
      <guid>https://d175uvn6dnkepf.cloudfront.net/post/ai-based-drug-discovery-with-atomwise-and-weka-data-platform.html</guid>
      <description>Drug discovery is an expensive proposition, with a $2.6 billion cost over 10 years and just a 12% success rate. AI promises to significantly improve the success rate by finding small molecule hits for undruggable targets. On the forefront of using AI in drug discovery is Atomwise, with its AtomNet® platform. In this blog, we will lay out the challenges of the drug discovery process, and show how AI/ML startups are solving these challenges using solutions from Atomwise, AWS, and WEKA.
Read the full post at the AWS HPC Blog.</description>
    </item>
    
    <item>
      <title>Scalable and Cost-Effective Batch Processing for ML workloads with AWS Batch and Amazon FSx</title>
      <link>https://d175uvn6dnkepf.cloudfront.net/post/scalable-and-cost-effective-batch-processing-for-ml-workloads-with-aws-batch-and-amazon-fsx.html</link>
      <pubDate>Fri, 23 Jul 2021 00:00:00 -0700</pubDate>
      
      <guid>https://d175uvn6dnkepf.cloudfront.net/post/scalable-and-cost-effective-batch-processing-for-ml-workloads-with-aws-batch-and-amazon-fsx.html</guid>
      <description>Batch processing is a common need across varied machine learning use cases such as video production, financial modeling, drug discovery, or genomic research. The elasticity of the cloud provides efficient ways to scale and simplify batch processing workloads while cutting costs. In this post, you’ll learn a scalable and cost-effective approach to configure AWS Batch Array jobs to process datasets that are stored on Amazon S3 and presented to compute instances with Amazon FSx for Lustre.
Read the full post at the AWS HPC Blog.</description>
    </item>
    
    <item>
      <title>Accelerating research and development of new medical treatments with HPC on AWS</title>
      <link>https://d175uvn6dnkepf.cloudfront.net/post/accelerating-research-and-development-of-new-medical-treatments-with-hpc-on-aws.html</link>
      <pubDate>Fri, 28 May 2021 00:00:00 -0700</pubDate>
      
      <guid>https://d175uvn6dnkepf.cloudfront.net/post/accelerating-research-and-development-of-new-medical-treatments-with-hpc-on-aws.html</guid>
      <description>Today, more than 290,000 researchers in France are working to provide better support and care for patients through modern medical treatment. To fulfill their mission, these researchers must be equipped with powerful tools. At AWS, we believe that technology has a critical role to play in medical research. Why? Because technology can take advantage of the significant amount of data generated in the healthcare system and in the research community to enable opportunities for more accurate diagnoses, and better treatments for many existing and future diseases. To support elite research in France, we are proud to be a sponsor of two French organizations: Gustave Roussy and Sorbonne University. AWS is providing them with the computing power and machine learning technologies needed to accelerate cancer research and develop a treatment for COVID-19.
Read the full post at the AWS HPC Blog.</description>
    </item>
    
    <item>
      <title>How EFA works and why we don&#39;t use infiniband in the cloud.</title>
      <link>https://d175uvn6dnkepf.cloudfront.net/post/how-efa-works-and-why-we-dont-use-infiniband-in-the-cloud.html</link>
      <pubDate>Thu, 13 May 2021 15:00:17 +0000</pubDate>
      
      <guid>https://d175uvn6dnkepf.cloudfront.net/post/how-efa-works-and-why-we-dont-use-infiniband-in-the-cloud.html</guid>
      <description>AWS’s compute infrastructure is very much not like a ‘normal’ supercomputer (whatever that is). We don’t start with a blank page every few years and design the next big system. It’s more like a city where we have to build on what’s there already, renovate occasionally, and push for bigger and better and faster whilst keeping the lights on at all times.
That leads to a bunch of design decisions that drive our engineers in a very different direction and our Elastic Fabric Adapter is an example of just that. Brian Barrett (one of our Principal Engineers in the HPC team) joins us this week to talk about the genesis of EFA, how it works, and why it convinced us that we could do without specialist fabrics like Infiniband and still deliver the same (or better) application scaling performance that our HPC customers were pushing us for.</description>
    </item>
    
  </channel>
</rss>
